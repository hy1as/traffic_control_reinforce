"""
λ§μ¤ν„° μ‹¤ν— μ¤ν¬λ¦½νΈ
ν•μ΄νΌνλΌλ―Έν„° νλ‹ β†’ μµμ  νλΌλ―Έν„°λ΅ μ‹λ‚λ¦¬μ¤ λΉ„κµ μλ™ μ‹¤ν–‰
"""

import os
import sys
import subprocess
import json


def run_command(cmd: str, description: str):
    """λ…λ Ήμ–΄ μ‹¤ν–‰"""
    print("\n" + "="*70)
    print(f"π€ {description}")
    print("="*70)
    print(f"λ…λ Ήμ–΄: {cmd}\n")
    
    result = subprocess.run(cmd, shell=True)
    
    if result.returncode != 0:
        print(f"\nβ μ¤λ¥ λ°μƒ: {description}")
        sys.exit(1)
    
    print(f"\nβ… μ™„λ£: {description}")


def check_tuning_results_exist() -> bool:
    """ν•μ΄νΌνλΌλ―Έν„° νλ‹ κ²°κ³Ό μ΅΄μ¬ ν™•μΈ"""
    return os.path.exists('./results/hyperparameter_tuning_results.json')


def master_workflow(mode: str = 'full'):
    """
    λ§μ¤ν„° μ›ν¬ν”λ΅μ°
    
    Args:
        mode: 'full' (μ „μ²΄), 'skip-tuning' (νλ‹ μ¤ν‚µ)
    """
    print("\n" + "="*70)
    print("π― κ°•ν™”ν•™μµ κµν†µ μ‹ νΈλ“± μ μ–΄ - λ§μ¤ν„° μ‹¤ν— μ›ν¬ν”λ΅μ°")
    print("="*70)
    print(f"μ‹¤ν–‰ λ¨λ“: {mode.upper()}")
    print("="*70)
    
    if mode == 'skip-tuning':
        # νλ‹ μ¤ν‚µ λ¨λ“ (κΈ°λ³Έ νλΌλ―Έν„° μ‚¬μ©)
        print("\nπ“ νλ‹ μ¤ν‚µ λ¨λ“")
        print("   - κΈ°λ³Έ ν•μ΄νΌνλΌλ―Έν„° μ‚¬μ©")
        print("   - μ‹λ‚λ¦¬μ¤ λΉ„κµ μ‹¤ν—λ§ μν–‰")
        print("   - μμƒ μ†μ” μ‹κ°„: μ•½ 4-6μ‹κ°„\n")
        
        # ν†µν•© μ›ν¬ν”λ΅μ° (κΈ°λ³Έ νλΌλ―Έν„°)
        run_command(
            "python integrated_workflow.py --train-episodes 2000 --eval-episodes 100",
            "μ‹λ‚λ¦¬μ¤ λΉ„κµ μ‹¤ν— (κΈ°λ³Έ νλΌλ―Έν„°)"
        )
        
        print("\n" + "="*70)
        print("β¨ μ‹¤ν— μ™„λ£!")
        print("="*70)
        
    elif mode == 'full':
        # μ „μ²΄ μ‹¤ν— λ¨λ“
        print("\nπ“ μ „μ²΄ μ‹¤ν— λ¨λ“")
        print("   - 1λ‹¨κ³„: ν•μ΄νΌνλΌλ―Έν„° νλ‹ (μ‹¤ν— A~D)")
        print("   - 2λ‹¨κ³„: μµμ  νλΌλ―Έν„°λ΅ μ‹λ‚λ¦¬μ¤ λΉ„κµ")
        # 1λ‹¨κ³„: ν•μ΄νΌνλΌλ―Έν„° νλ‹
        if not check_tuning_results_exist():
            run_command(
                "python hyperparameter_tuning.py",
                "1λ‹¨κ³„: ν•μ΄νΌνλΌλ―Έν„° νλ‹ (μ‹¤ν— A~D)"
            )
        else:
            print("\nβ… ν•μ΄νΌνλΌλ―Έν„° νλ‹ κ²°κ³Ό μ΄λ―Έ μ΅΄μ¬")
            print("   κΈ°μ΅΄ κ²°κ³Όλ¥Ό μ‚¬μ©ν•©λ‹λ‹¤.")
        
        # 2λ‹¨κ³„: μµμ  νλΌλ―Έν„°λ΅ μ‹λ‚λ¦¬μ¤ λΉ„κµ
        run_command(
            "python integrated_workflow.py --use-tuned --train-episodes 2000 --eval-episodes 100",
            "2λ‹¨κ³„: μ‹λ‚λ¦¬μ¤ λΉ„κµ (μµμ  νλΌλ―Έν„°)"
        )
        
        print("\n" + "="*70)
        print("β¨ λ¨λ“  μ‹¤ν— μ™„λ£!")
        print("="*70)
        
        # κ²°κ³Ό νμΌ μ”μ•½
        print("\nπ“‚ μƒμ„±λ κ²°κ³Ό νμΌ:")
        print("   ./results/hyperparameter_tuning_results.json")
        print("   ./results/integrated_experiment_results.json")
        print("   ./results/plots/hyperparameter_*.png")
        print("   ./models/optimized/")
    
    else:
        print(f"β μ• μ μ—†λ” λ¨λ“: {mode}")
        print("   μ‚¬μ© κ°€λ¥ν• λ¨λ“: 'skip-tuning', 'full'")
        sys.exit(1)


def print_usage():
    """μ‚¬μ©λ²• μ¶λ ¥"""
    print("""
β•”β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•—
β•‘        κ°•ν™”ν•™μµ κµν†µ μ‹ νΈλ“± μ μ–΄ - λ§μ¤ν„° μ‹¤ν— μ¤ν¬λ¦½νΈ            β•‘
β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•

μ‚¬μ©λ²•:
    python master_experiment.py [--mode MODE]

λ¨λ“ μµμ…:
    skip-tuning  : νλ‹ μ¤ν‚µ λ¨λ“ (~4-6μ‹κ°„)
                   - κΈ°λ³Έ νλΌλ―Έν„°λ΅ μ‹λ‚λ¦¬μ¤ λΉ„κµλ§ μν–‰
                   - ν•μ΄νΌνλΌλ―Έν„° νλ‹ κ±΄λ„λ›°κΈ°
    
    full         : μ „μ²΄ μ‹¤ν— (~12-16μ‹κ°„) β­ κ¶μ¥
                   - ν•μ΄νΌνλΌλ―Έν„° νλ‹ (μ‹¤ν— A~D)
                   - μµμ  νλΌλ―Έν„°λ΅ μ‹λ‚λ¦¬μ¤ λΉ„κµ

μμ‹:
    # μ „μ²΄ μ‹¤ν—
    python master_experiment.py --mode full
    
    # κΈ°λ³Έ νλΌλ―Έν„°λ΅ μ‹λ‚λ¦¬μ¤λ§ μ‹¤ν—
    python master_experiment.py --mode skip-tuning

μ‹¤ν— μ›ν¬ν”λ΅μ°:
    
    [Mode: skip-tuning]
    1. μ‹λ‚λ¦¬μ¤ λΉ„κµ (κΈ°λ³Έ νλΌλ―Έν„°)
       - normal, morning_rush, evening_rush, congestion, night
       - DQN vs Double DQN vs Baseline
    
    [Mode: full] β­β­β­
    1. ν•μ΄νΌνλΌλ―Έν„° νλ‹
       - μ‹¤ν— A: Learning Rate
       - μ‹¤ν— B: Discount Factor
       - μ‹¤ν— C: Batch Size
       - μ‹¤ν— D: Buffer Size
    
    2. μµμ  νλΌλ―Έν„° μλ™ μ„ νƒ
    
    3. μ‹λ‚λ¦¬μ¤ λΉ„κµ (μµμ  νλΌλ―Έν„°)
       - normal, morning_rush, evening_rush, congestion, night
       - DQN vs Double DQN vs Baseline

κ²°κ³Ό νμΌ:
    ./results/hyperparameter_tuning_results.json
    ./results/integrated_experiment_results.json
    ./results/plots/
    ./models/optimized/

β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•
    """)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description='κ°•ν™”ν•™μµ κµν†µ μ‹ νΈλ“± μ μ–΄ - λ§μ¤ν„° μ‹¤ν—',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--mode',
        type=str,
        default='full',
        choices=['skip-tuning', 'full'],
        help='μ‹¤ν— λ¨λ“ μ„ νƒ'
    )
    
    parser.add_argument(
        '--help-detail',
        action='store_true',
        help='μƒμ„Έ μ‚¬μ©λ²• μ¶λ ¥'
    )
    
    args = parser.parse_args()
    
    if args.help_detail:
        print_usage()
    else:
        master_workflow(mode=args.mode)